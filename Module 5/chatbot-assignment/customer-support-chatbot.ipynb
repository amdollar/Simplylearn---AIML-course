{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72e403d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52c3fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ef6479d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"order_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Order Id\"}, \"product_name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Product Name\"}, \"issue_type\": {\"default\": null, \"title\": \"Issue Type\", \"type\": \"string\"}, \"details\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Details\"}}}\\n```'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OrderQuery(BaseModel):\n",
    "    order_id: Optional [int]= None\n",
    "    product_name: Optional [str] =None\n",
    "    issue_type: str = None\n",
    "    details: Optional[str] = None\n",
    "\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object= OrderQuery)\n",
    "format_inst = parser.get_format_instructions()\n",
    "format_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d45d764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_query_prompt =ChatPromptTemplate.from_messages(\n",
    "                                            [\n",
    "                                                (\"system\",\n",
    "                                            \"You are and AI assistant for a e-commerce company, \"\n",
    "                                            \"You MUST extract the structured information from the customer's query. \\n\\n\"\n",
    "                                            \"{format_instructions}\"\n",
    "                                                ),\n",
    "                                          (\"human\",\n",
    "                                           \"query: {query}\"\n",
    "                                          )]\n",
    ")\n",
    "                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5538ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain:\n",
    "extracted_query_chain = user_query_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdfe89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id=23212 product_name=None issue_type='Order Status Inquiry' details=None\n",
      "order_id=None product_name='action camera' issue_type='suggestion' details='Find a good action camera under 10K.'\n",
      "order_id=91223 product_name=None issue_type='return' details='It is not working properly'\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    'Where is my order #23212',\n",
    "    'Suggest me a good action camera under 10K',\n",
    "    'I want to return my order #91223, It is not working properly'\n",
    "]\n",
    "for i in test_queries:\n",
    "    output = extracted_query_chain.invoke({'query':i, 'format_instructions': parser.get_format_instructions()})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100f5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'order_query': OrderQuery(order_id=23212, product_name=None, issue_type='Shipping Inquiry', details=None),\n",
       " 'error': None}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def _handle_validation_error(error: Exception) -> dict:\n",
    "    \"\"\"Formats a ValidationError into a structured error dictionary.\"\"\"\n",
    "    # Extract relevant error details, e.g., error.errors()\n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"order_query\": None,\n",
    "        \"error\": f\"Validation failed: {error}\"\n",
    "    }\n",
    "\n",
    "# Convert the error handler function into a RunnableLambda\n",
    "validation_error_handler = RunnableLambda(_handle_validation_error)\n",
    "\n",
    "def _format_final_output(result):\n",
    "    \"\"\"Formats the final output to be consistent for success or error cases.\"\"\"\n",
    "    if isinstance(result, OrderQuery):\n",
    "        return {\"success\": True, \"order_query\": result, \"error\": None}\n",
    "    else:  # This branch is for the error dict from validation_error_handler\n",
    "        return result\n",
    "\n",
    "# Replace the previous validation_step with a final formatter\n",
    "final_output_formatter = RunnableLambda(_format_final_output)\n",
    "\n",
    "# The order_validation_chain now uses with_fallbacks to catch ValidationErrors\n",
    "# and routes successful outputs or handled errors to the final formatter.\n",
    "order_validation_chain = (\n",
    "    user_query_prompt\n",
    "    | llm\n",
    "    | parser.with_fallbacks(\n",
    "        fallbacks=[validation_error_handler],\n",
    "        exceptions_to_handle=(ValidationError,)\n",
    "    )\n",
    "    | final_output_formatter # This step ensures consistent output format\n",
    ")\n",
    "     \n",
    "# Test with a working query (LLM should correctly provide issue_type)\n",
    "order_validation_chain.invoke({'query':'Where is my order #23212', 'format_instructions': parser.get_format_instructions()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
