{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7425a13",
   "metadata": {},
   "source": [
    "# Assignment: Router Chains (Runnables) + `@chain` Decorator (Use‑Case Based)\n",
    "\n",
    "**What you just learned:**  \n",
    "- Routing with LangChain **Runnables** (e.g., `RunnableBranch`, router functions, conditional flows)  \n",
    "- Writing reusable chains with the **`@chain`** decorator\n",
    "\n",
    "**Goal of this assignment:** Build **use‑case driven routers** that select the right prompt/chain based on the user input, enforce structured outputs, and add simple evaluation checks.\n",
    "\n",
    "---\n",
    "\n",
    "## Rules\n",
    "1. Do **not** hardcode answers.  \n",
    "2. Your router must be deterministic given the same input (no random routing).  \n",
    "3. Use **at least one** `@chain` decorated function in each use case.  \n",
    "4. Add minimal guardrails: if unsure, route to a safe fallback that asks clarifying questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51956f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.runnables import RunnableLambda, RunnableBranch, RunnablePassthrough, chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "llm  = ChatOpenAI(model='gpt-4o-mini')\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417be38",
   "metadata": {},
   "source": [
    "1) Warm‑up (Mini task)\n",
    "Task\n",
    "\n",
    "Create a tiny @chain called normalize_query that:\n",
    "\n",
    "strips extra spaces\n",
    "converts to lowercase\n",
    "returns the cleaned string\n",
    "Then test it on:\n",
    "\" Refund Status for Order #1234 \"\n",
    "\n",
    "Expected behavior (example):\n",
    "\"refund status for order #1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7bdfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'refund status for order #1234'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "@chain\n",
    "def normalize_query(input):\n",
    "\n",
    "    return input.strip().lower()\n",
    "\n",
    "normalized_output = normalize_query.invoke(' Refund Status for Order #1234 ')\n",
    "normalized_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61b702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
