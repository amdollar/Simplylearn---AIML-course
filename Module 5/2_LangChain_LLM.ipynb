{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3c679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_model = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506ca8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_model.invoke('Explain me what is LangChain, keep it short and concise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718a23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed for building applications powered by language models. It provides tools for integrating various components such as APIs, databases, and document storage, enabling developers to create complex workflows involving natural language processing. LangChain facilitates easy interaction with large language models by structuring tasks like data retrieval, conversation management, and prompt generation, making it easier to develop, deploy, and iterate NLP applications.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df777c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for using different types of Messages: \n",
    "# 1. SystemMessage: helps to setup persona\n",
    "# 2. HumanMessage: User input\n",
    "# 3. AIMessage: Response from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31f56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Temperature\n",
    "# temperature decides whether to emit facts or be creative\n",
    "#\n",
    "# 0 ----------- model will only emit facts\n",
    "# 1 ----------- model will be super creative\n",
    "#\n",
    "# 0 -------------------------------- 1\n",
    "# Factual                         Creative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_question = HumanMessage('Tell me System Design Hacks in 3 points.')\n",
    "system_persona = SystemMessage('Act as a top tech interviewer, your answers will be on point.')\n",
    "\n",
    "message = [system_persona, human_question]\n",
    "\n",
    "print(llm.invoke(message).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
