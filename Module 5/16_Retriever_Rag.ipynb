{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827f3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Read the document.\n",
    "2. Splitting document.\n",
    "3. Perform Embedding\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0044dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "LangChain is an open-source framework for building applications with large language models (LLMs).\n",
    "It allows developers to combine LLMs with external data sources, APIs, and custom logic.\n",
    "Retrieval-Augmented Generation (RAG) is a technique that combines information retrieval and LLMs\n",
    "to answer questions with up-to-date, domain-specific, or long-tail knowledge.\n",
    "\n",
    "Anurag Awasthi is one of the best trainers of AI.\n",
    "'''\n",
    "\n",
    "with open('rag.text', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c714a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'rag.text'}, page_content='\\nLangChain is an open-source framework for building applications with large language models (LLMs).\\nIt allows developers to combine LLMs with external data sources, APIs, and custom logic.\\nRetrieval-Augmented Generation (RAG) is a technique that combines information retrieval and LLMs\\nto answer questions with up-to-date, domain-specific, or long-tail knowledge.\\n\\nAnurag Awasthi is one of the best trainers of AI.\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(file_path='rag.text')\n",
    "doc = loader.load()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66173b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1 : data: Lang\n",
      "chunk number: 2 : data: angCh\n",
      "chunk number: 3 : data: gChai\n",
      "chunk number: 4 : data: hain\n",
      "chunk number: 5 : data: is\n",
      "chunk number: 6 : data: an\n",
      "chunk number: 7 : data: open\n",
      "chunk number: 8 : data: pen-s\n",
      "chunk number: 9 : data: n-sou\n",
      "chunk number: 10 : data: sourc\n",
      "chunk number: 11 : data: urce\n",
      "chunk number: 12 : data: fram\n",
      "chunk number: 13 : data: ramew\n",
      "chunk number: 14 : data: mewor\n",
      "chunk number: 15 : data: work\n",
      "chunk number: 16 : data: for\n",
      "chunk number: 17 : data: buil\n",
      "chunk number: 18 : data: uildi\n",
      "chunk number: 19 : data: lding\n",
      "chunk number: 20 : data: appl\n",
      "chunk number: 21 : data: pplic\n",
      "chunk number: 22 : data: licat\n",
      "chunk number: 23 : data: catio\n",
      "chunk number: 24 : data: tions\n",
      "chunk number: 25 : data: with\n",
      "chunk number: 26 : data: larg\n",
      "chunk number: 27 : data: arge\n",
      "chunk number: 28 : data: lang\n",
      "chunk number: 29 : data: angua\n",
      "chunk number: 30 : data: guage\n",
      "chunk number: 31 : data: mode\n",
      "chunk number: 32 : data: odels\n",
      "chunk number: 33 : data: (LLM\n",
      "chunk number: 34 : data: LLMs)\n",
      "chunk number: 35 : data: Ms).\n",
      "chunk number: 36 : data: It\n",
      "chunk number: 37 : data: allo\n",
      "chunk number: 38 : data: llows\n",
      "chunk number: 39 : data: deve\n",
      "chunk number: 40 : data: evelo\n",
      "chunk number: 41 : data: elope\n",
      "chunk number: 42 : data: opers\n",
      "chunk number: 43 : data: to\n",
      "chunk number: 44 : data: comb\n",
      "chunk number: 45 : data: ombin\n",
      "chunk number: 46 : data: bine\n",
      "chunk number: 47 : data: LLMs\n",
      "chunk number: 48 : data: with\n",
      "chunk number: 49 : data: exte\n",
      "chunk number: 50 : data: xtern\n",
      "chunk number: 51 : data: ernal\n",
      "chunk number: 52 : data: data\n",
      "chunk number: 53 : data: sour\n",
      "chunk number: 54 : data: ource\n",
      "chunk number: 55 : data: rces,\n",
      "chunk number: 56 : data: APIs\n",
      "chunk number: 57 : data: PIs,\n",
      "chunk number: 58 : data: and\n",
      "chunk number: 59 : data: cust\n",
      "chunk number: 60 : data: ustom\n",
      "chunk number: 61 : data: logi\n",
      "chunk number: 62 : data: ogic.\n",
      "chunk number: 63 : data: Retr\n",
      "chunk number: 64 : data: etrie\n",
      "chunk number: 65 : data: rieva\n",
      "chunk number: 66 : data: eval-\n",
      "chunk number: 67 : data: al-Au\n",
      "chunk number: 68 : data: -Augm\n",
      "chunk number: 69 : data: ugmen\n",
      "chunk number: 70 : data: mente\n",
      "chunk number: 71 : data: nted\n",
      "chunk number: 72 : data: Gene\n",
      "chunk number: 73 : data: enera\n",
      "chunk number: 74 : data: erati\n",
      "chunk number: 75 : data: ation\n",
      "chunk number: 76 : data: (RAG\n",
      "chunk number: 77 : data: RAG)\n",
      "chunk number: 78 : data: is a\n",
      "chunk number: 79 : data: tech\n",
      "chunk number: 80 : data: echni\n",
      "chunk number: 81 : data: hniqu\n",
      "chunk number: 82 : data: ique\n",
      "chunk number: 83 : data: that\n",
      "chunk number: 84 : data: comb\n",
      "chunk number: 85 : data: ombin\n",
      "chunk number: 86 : data: bines\n",
      "chunk number: 87 : data: info\n",
      "chunk number: 88 : data: nform\n",
      "chunk number: 89 : data: ormat\n",
      "chunk number: 90 : data: matio\n",
      "chunk number: 91 : data: tion\n",
      "chunk number: 92 : data: retr\n",
      "chunk number: 93 : data: etrie\n",
      "chunk number: 94 : data: rieva\n",
      "chunk number: 95 : data: eval\n",
      "chunk number: 96 : data: and\n",
      "chunk number: 97 : data: LLMs\n",
      "chunk number: 98 : data: to\n",
      "chunk number: 99 : data: answ\n",
      "chunk number: 100 : data: nswer\n",
      "chunk number: 101 : data: ques\n",
      "chunk number: 102 : data: uesti\n",
      "chunk number: 103 : data: stion\n",
      "chunk number: 104 : data: ions\n",
      "chunk number: 105 : data: with\n",
      "chunk number: 106 : data: up-t\n",
      "chunk number: 107 : data: p-to-\n",
      "chunk number: 108 : data: to-da\n",
      "chunk number: 109 : data: -date\n",
      "chunk number: 110 : data: ate,\n",
      "chunk number: 111 : data: doma\n",
      "chunk number: 112 : data: omain\n",
      "chunk number: 113 : data: ain-s\n",
      "chunk number: 114 : data: n-spe\n",
      "chunk number: 115 : data: speci\n",
      "chunk number: 116 : data: ecifi\n",
      "chunk number: 117 : data: ific,\n",
      "chunk number: 118 : data: or\n",
      "chunk number: 119 : data: long\n",
      "chunk number: 120 : data: ong-t\n",
      "chunk number: 121 : data: g-tai\n",
      "chunk number: 122 : data: tail\n",
      "chunk number: 123 : data: know\n",
      "chunk number: 124 : data: nowle\n",
      "chunk number: 125 : data: wledg\n",
      "chunk number: 126 : data: edge.\n",
      "chunk number: 127 : data: Anur\n",
      "chunk number: 128 : data: nurag\n",
      "chunk number: 129 : data: Awas\n",
      "chunk number: 130 : data: wasth\n",
      "chunk number: 131 : data: sthi\n",
      "chunk number: 132 : data: is\n",
      "chunk number: 133 : data: one\n",
      "chunk number: 134 : data: of\n",
      "chunk number: 135 : data: the\n",
      "chunk number: 136 : data: best\n",
      "chunk number: 137 : data: trai\n",
      "chunk number: 138 : data: raine\n",
      "chunk number: 139 : data: iners\n",
      "chunk number: 140 : data: of\n",
      "chunk number: 141 : data: AI.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size= 5, chunk_overlap= 3)\n",
    "chunks = splitter.split_documents(doc)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f'chunk number: {i+1} : data: {chunk.page_content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e79972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: 141\n"
     ]
    }
   ],
   "source": [
    "# Embedding \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "chunk_list = [c.page_content for c in chunks]\n",
    "vector = embeddings.embed_documents(chunk_list)\n",
    "\n",
    "print(f'Vector shape: {len(vector)}')\n",
    "\n",
    "# We need to store this vector (Embedded format of docs into a vector database, for further uses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the vector storage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
