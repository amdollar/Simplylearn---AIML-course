{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70204faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    ChatPromptTemplate,\n",
    "                                    PromptTemplate)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b7f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7640c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Declearing a Pydantic Object: Kind of declearing a schema, \n",
    "# This schema can be used as a OutputParser to generate the output in this schema format\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description='The setup of the Joke')\n",
    "    punchline: str= Field(description='The punchline of the Joke')\n",
    "    rating : Optional[int] = Field(description='The rating for overall joke from 1 to 10', default=None, ge=1, le=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analogy ---- Create a table named Joke which has 3 columns\n",
    "#             setup : str , not null\n",
    "#             punchline: str , not null\n",
    "#             rating: int , null, None\n",
    "\n",
    "#\n",
    "# Constraints for Field object\n",
    "#==============================\n",
    "# ge --- greater than equal to\n",
    "# le --- less than equal to\n",
    "# gt --- greater than\n",
    "# lt --- less than\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object= Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6628abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the Joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the Joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"maximum\": 10, \"minimum\": 1, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating for overall joke from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = parser.get_format_instructions() #Extract prompt that you may use in the prompt template\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f77d735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"setup\": \"Why did the cat sit on the computer?\",\n",
      "  \"punchline\": \"Because it wanted to keep an eye on the mouse!\",\n",
      "  \"rating\": 7\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Using this : \n",
    "# There are two ways: Directly use it as we have seen till now as | parser\n",
    "# Using Pydantic object inside the prompt (Format Instructions)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "Answer the query with the joke. Here is your formatting instructions.\n",
    "{format_instruction}\n",
    "query: {query}\n",
    "Answer: \"\"\",\n",
    "\n",
    "# 'input_variables' specifies which keys the template expects at runtime (here: 'query')\n",
    "\n",
    "input_variable= ['query'],\n",
    "\n",
    "# 'partial_variables' are values you want to \"hard-code\" or fill in at creation time.\n",
    "# Here, format_instruction is filled automatically with instructions from the parser\n",
    "partial_variables= {'format_instruction': parser.get_format_instructions()}\n",
    ")   \n",
    "\n",
    "# The result is a prompt template that, when given a 'query', will fill in both\n",
    "# 'query' (user's actual question) and 'format_instruction' (instructions for output formatting).\n",
    "\n",
    "# Step 2: Create a chain by connecting the prompt template to the LLM\n",
    "# This means: the input dict will first fill the prompt, then be sent to the LLM.\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "output = chain.invoke({\n",
    "    'query':'Tell me a joke abouve the cat'\n",
    "})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86155e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog sit in the shade?' punchline=\"Because he didn't want to become a hot dog!\" rating=7\n"
     ]
    }
   ],
   "source": [
    "# Way 2: Directly using as parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'Tell me a joke about Dog'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a63ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do elephants never use computers?\n",
      "\n",
      "Because they're afraid of the mouse! üêòüñ±Ô∏è\n",
      "setup=\"Why don't elephants use computers?\" punchline=\"Because they're afraid of the mouse!\" rating=8\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Passing pydantic object directly to LLM:\n",
    "\n",
    "# Simple call:\n",
    "\n",
    "output = llm.invoke('Tell me a Joke about Elephant')\n",
    "print(output.content)\n",
    "\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_output = structured_llm.invoke('Tell me a Joke about Elephant')\n",
    "print(structured_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
