{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain langchain-core langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70204faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    ChatPromptTemplate,\n",
    "                                    PromptTemplate)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser, JsonOutputParser\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser \n",
    "# Correct\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Declearing a Pydantic Object: Kind of declearing a schema, \n",
    "# This schema can be used as a OutputParser to generate the output in this schema format\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description='The setup of the Joke')\n",
    "    punchline: str= Field(description='The punchline of the Joke')\n",
    "    rating : Optional[int] = Field(description='The rating for overall joke from 1 to 10', default=None, ge=1, le=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analogy ---- Create a table named Joke which has 3 columns\n",
    "#             setup : str , not null\n",
    "#             punchline: str , not null\n",
    "#             rating: int , null, None\n",
    "\n",
    "#\n",
    "# Constraints for Field object\n",
    "#==============================\n",
    "# ge --- greater than equal to\n",
    "# le --- less than equal to\n",
    "# gt --- greater than\n",
    "# lt --- less than\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object= Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6628abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the Joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the Joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"maximum\": 10, \"minimum\": 1, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating for overall joke from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = parser.get_format_instructions() #Extract prompt that you may use in the prompt template\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!\n"
     ]
    }
   ],
   "source": [
    "# Using this : \n",
    "# 1. Using Pydantic object inside the prompt (Format Instructions)\n",
    "# 2. There are two ways: Directly use it as we have seen till now as | parser\n",
    "# 3: Passing pydantic object directly to LLM:\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "Answer the query with the joke. Here is your formatting instructions.\n",
    "{format_instruction}\n",
    "query: {query}\n",
    "Answer: \"\"\",\n",
    "\n",
    "# 'input_variables' specifies which keys the template expects at runtime (here: 'query')\n",
    "\n",
    "input_variable= ['query'],\n",
    "\n",
    "# 'partial_variables' are values you want to \"hard-code\" or fill in at creation time.\n",
    "# Here, format_instruction is filled automatically with instructions from the parser\n",
    "partial_variables= {'format_instruction': parser.get_format_instructions()}\n",
    ")   \n",
    "\n",
    "# The result is a prompt template that, when given a 'query', will fill in both\n",
    "# 'query' (user's actual question) and 'format_instruction' (instructions for output formatting).\n",
    "\n",
    "# Step 2: Create a chain by connecting the prompt template to the LLM\n",
    "# This means: the input dict will first fill the prompt, then be sent to the LLM.\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "output = chain.invoke({\n",
    "    'query':'Tell me a joke abouve the cat'\n",
    "})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86155e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog sit in the shade?' punchline=\"Because he didn't want to become a hot dog!\" rating=7\n"
     ]
    }
   ],
   "source": [
    "# Way 2: Directly using as parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'Tell me a joke about Dog'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a63ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do elephants never use computers?\n",
      "\n",
      "Because they're afraid of the mouse! üêòüñ±Ô∏è\n",
      "setup=\"Why don't elephants use computers?\" punchline=\"Because they're afraid of the mouse!\" rating=8\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Passing pydantic object directly to LLM:\n",
    "\n",
    "# Simple call:\n",
    "\n",
    "output = llm.invoke('Tell me a Joke about Elephant')\n",
    "print(output.content)\n",
    "\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_output = structured_llm.invoke('Tell me a Joke about Elephant')\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d90878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT OUTPUT FORMAT:\n",
      "- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\n",
      "- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\n",
      "- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\n",
      "- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema (shown in a code block for readability only ‚Äî do not include any backticks or Markdown in your output):\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the Joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the Joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"maximum\": 10, \"minimum\": 1, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating for overall joke from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(json_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c895dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\":\"Why do programmers prefer dark mode?\",\"punchline\":\"Because light attracts bugs!\",\"rating\":8}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Answer the user query with a Joke, here are the formatting instructions:\n",
    "{format_instruction}\n",
    "Query: {query}\n",
    "Answer: \"\"\",\n",
    "\n",
    "input_variables=['query'],\n",
    "partial_variables={'format_instruction': json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({\n",
    "    'query':'Tell me a joke about computer science'\n",
    "})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605983b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP, LLM, natural language processing, language models, machine learning, AI, artificial intelligence, text analysis, deep learning, conversational AI, data science, semantic analysis, language understanding, chatbot development, speech recognition, sentiment analysis'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=\"\"\"\n",
    "Answer the user query with the list of values. Here is your formatting instruction.\n",
    "                        {format_instruction},\n",
    "                        query: {query},\n",
    "                        Answer:  \n",
    "\"\"\", \n",
    "input_variables = ['query'],\n",
    "partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "output = chain.invoke({'query':  'generate my website seo keywords. I have content about the NLP and LLM.'})\n",
    "\n",
    "output.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
