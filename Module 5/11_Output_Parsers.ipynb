{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff5c6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\thedo\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\thedo\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\thedo\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\thedo\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-core) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\thedo\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain langchain-core langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70204faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    ChatPromptTemplate,\n",
    "                                    PromptTemplate)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser, JsonOutputParser\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser \n",
    "# Correct\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8b7f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7640c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Declearing a Pydantic Object: Kind of declearing a schema, \n",
    "# This schema can be used as a OutputParser to generate the output in this schema format\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description='The setup of the Joke')\n",
    "    punchline: str= Field(description='The punchline of the Joke')\n",
    "    rating : Optional[int] = Field(description='The rating for overall joke from 1 to 10', default=None, ge=1, le=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29a017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analogy ---- Create a table named Joke which has 3 columns\n",
    "#             setup : str , not null\n",
    "#             punchline: str , not null\n",
    "#             rating: int , null, None\n",
    "\n",
    "#\n",
    "# Constraints for Field object\n",
    "#==============================\n",
    "# ge --- greater than equal to\n",
    "# le --- less than equal to\n",
    "# gt --- greater than\n",
    "# lt --- less than\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object= Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6628abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the Joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the Joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"maximum\": 10, \"minimum\": 1, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating for overall joke from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = parser.get_format_instructions() #Extract prompt that you may use in the prompt template\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f77d735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"setup\": \"Why did the cat sit on the computer?\",\n",
      "  \"punchline\": \"Because it wanted to keep an eye on the mouse!\",\n",
      "  \"rating\": 7\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Using this : \n",
    "# 1. Using Pydantic object inside the prompt (Format Instructions)\n",
    "# 2. There are two ways: Directly use it as we have seen till now as | parser\n",
    "# 3: Passing pydantic object directly to LLM:\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "Answer the query with the joke. Here is your formatting instructions.\n",
    "{format_instruction}\n",
    "query: {query}\n",
    "Answer: \"\"\",\n",
    "\n",
    "# 'input_variables' specifies which keys the template expects at runtime (here: 'query')\n",
    "\n",
    "input_variable= ['query'],\n",
    "\n",
    "# 'partial_variables' are values you want to \"hard-code\" or fill in at creation time.\n",
    "# Here, format_instruction is filled automatically with instructions from the parser\n",
    "partial_variables= {'format_instruction': parser.get_format_instructions()}\n",
    ")   \n",
    "\n",
    "# The result is a prompt template that, when given a 'query', will fill in both\n",
    "# 'query' (user's actual question) and 'format_instruction' (instructions for output formatting).\n",
    "\n",
    "# Step 2: Create a chain by connecting the prompt template to the LLM\n",
    "# This means: the input dict will first fill the prompt, then be sent to the LLM.\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "output = chain.invoke({\n",
    "    'query':'Tell me a joke abouve the cat'\n",
    "})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86155e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog sit in the shade?' punchline=\"Because he didn't want to become a hot dog!\" rating=7\n"
     ]
    }
   ],
   "source": [
    "# Way 2: Directly using as parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'Tell me a joke about Dog'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96a63ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do elephants never use computers?\n",
      "\n",
      "Because they're afraid of the mouse!\n",
      "setup=\"Why don't elephants use computers?\" punchline=\"Because they're afraid of the mouse!\" rating=7\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Passing pydantic object directly to LLM:\n",
    "\n",
    "# Simple call:\n",
    "\n",
    "output = llm.invoke('Tell me a Joke about Elephant')\n",
    "print(output.content)\n",
    "\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_output = structured_llm.invoke('Tell me a Joke about Elephant')\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06d90878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT OUTPUT FORMAT:\n",
      "- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\n",
      "- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\n",
      "- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\n",
      "- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema (shown in a code block for readability only â€” do not include any backticks or Markdown in your output):\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the Joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the Joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"maximum\": 10, \"minimum\": 1, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating for overall joke from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(json_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c895dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\":\"Why do programmers prefer dark mode?\",\"punchline\":\"Because light attracts bugs!\",\"rating\":8}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Answer the user query with a Joke, here are the formatting instructions:\n",
    "{format_instruction}\n",
    "Query: {query}\n",
    "Answer: \"\"\",\n",
    "\n",
    "input_variables=['query'],\n",
    "partial_variables={'format_instruction': json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({\n",
    "    'query':'Tell me a joke about computer science'\n",
    "})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "605983b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a56c052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP, LLM, natural language processing, language models, machine learning, artificial intelligence, text analysis, deep learning, chatbot technology, semantic understanding, data science, AI applications, language generation, speech recognition, sentiment analysis'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=\"\"\"\n",
    "Answer the user query with the list of values. Here is your formatting instruction.\n",
    "                        {format_instruction},\n",
    "                        query: {query},\n",
    "                        Answer:  \n",
    "\"\"\", \n",
    "input_variables = ['query'],\n",
    "partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "output = chain.invoke({'query':  'generate my website seo keywords. I have content about the NLP and LLM.'})\n",
    "\n",
    "output.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
