{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ad3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435640bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99923a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import mannwhitneyu\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779eb51f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e60d1e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task_1_data_import_verification():\n",
    "    \"\"\"Task 1: Examine variables like Dt_Customer and Income to verify importation. \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Task 1 : Data import verification:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = pd.read_csv('marketing_data.csv')\n",
    "\n",
    "    print(f\"\\n Dataset shape: {df.shape}\")\n",
    "    print(f\"\\n Dt_Customer examination: \")\n",
    "    print(f\" Data Type: {df['Dt_Customer'].dtype}\")\n",
    "    print(f\" Sample values: {df['Dt_Customer'].head(3).tolist()}\")\n",
    "    print(f\" Date Range: {df['Dt_Customer'].min()} to {df['Dt_Customer'].max()}\")\n",
    "\n",
    "    print(f\"\\n Income examination: \")\n",
    "    print(f\" Data type: {df[' Income '].dtype}\")\n",
    "    print(f\"Sample Values: {df[' Income '].head(3).tolist()}\")\n",
    "    print(f\"Missing Values: {df[' Income '].isna().sum()}\")\n",
    "\n",
    "    print(f\"\\n Total missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_missing_data_imputation(df):\n",
    "    \"\"\"Task 2: Handle the missing values and clean categorical data:\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Task2 : Missing value imputation\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    print(f\"\\n Education categories: {df_clean['Education'].unique().tolist()}\")\n",
    "    print(f\"\\n Marital status categories: {df_clean['Marital_Status'].unique().tolist()}\")\n",
    "\n",
    "\n",
    "    # Clean unusual Marital status:\n",
    "    status_mapping = {'YOLO':'Single', 'Absurd': 'Single', 'Alone': 'Single'}\n",
    "    df_clean['Marital_Status'] = df_clean['Marital_Status'].replace(status_mapping)\n",
    "    print(f\"Cleaned martial status mapping: {status_mapping}\")\n",
    "    print(f\"\\n Marital status categories: {df_clean['Marital_Status'].unique().tolist()}\")\n",
    "\n",
    "    # Process Income:\n",
    "    df_clean['Income'] = df_clean[' Income '].str.replace('$', '').str.replace(',', '').str.strip()\n",
    "    df_clean['Income'] = pd.to_numeric(df_clean['Income'], errors='coerce')\n",
    "\n",
    "    missing_before = df_clean['Income'].isnull().sum()\n",
    "    income_median= df_clean.groupby(['Education', 'Marital_Status'])['Income'].median()\n",
    "\n",
    "    \n",
    "    def impute_income(row):\n",
    "        if pd.isna(row['Income']):\n",
    "            key = (row['Education'], row['Marital_Status'])\n",
    "            return income_median.get(key, df_clean.groupby('Education')['Income'].median()[row['Education']])\n",
    "        \n",
    "        return row['Income']\n",
    "    \n",
    "    # Understand this more:\n",
    "    df_clean['Income'] = df_clean.apply(impute_income, axis=1)\n",
    "    \n",
    "    missing_after = df_clean['Income'].isnull().sum()\n",
    "\n",
    "    print(f\"\\nMissing income values - Before: {missing_before}, After: {missing_after}\")\n",
    "    print(f\"Income Range: ${df_clean['Income'].min():,.0f} -  ${df_clean['Income'].max():,.0f}\")\n",
    "\n",
    "    # Removed space's col name from data set \n",
    "    df_clean = df_clean.drop(' Income ', axis = 1)\n",
    " \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3_feature_engineering(df):\n",
    "    \"\"\"Task 3: Create new variables: \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Task 3: Feature Engineering\")\n",
    "    print(\"=\" * 60) \n",
    "\n",
    "    df['Total_Children']  = df['Kidhome'] + df['Teenhome']\n",
    "    children_dist = df['Total_Children'].value_counts().sort_index()\n",
    "    print(f\"\\n Total Children: {dict(children_dist)} (0= {children_dist[0]/len(df) * 100:.1f}%, 1+={100-children_dist[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "    #Age, Spending and purchase\n",
    "    df['Age'] = 2014-df['Year_Birth']\n",
    "    spending_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "    df['Total_Spending'] = df[spending_cols].sum(axis = 1)\n",
    "    purchase_cols= ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n",
    "    df['Total_Purchases'] = df[purchase_cols].sum(axis= 1)\n",
    "\n",
    "    print(f\"Age: {df['Age'].min()}-{df['Age'].max()} (avg: {df['Age'].mean():.1f})\")\n",
    "    print(f\"Spendings: $ {df['Total_Spending'].min():,.0f} - ${df['Total_Spending'].max():,.0f} (avg: {df['Total_Spending'].mean():.0f})\")\n",
    "    print(f\"Purchases: {df['Total_Purchases'].min()}-{df['Total_Purchases'].max()} (avg:{df['Total_Purchases'].mean():.1f})\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ba7d6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task_4_distributed_analysis_outliers(df):\n",
    "    \"\"\"Task 4: Generate box plots and Histrograms, identify outliers\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Task 4: Distributaion analysis and Outliers\")\n",
    "    print(\"=\" * 60) \n",
    "\n",
    "    numerical_cols = ['Age', 'Income', 'Total_Children','Total_Spending', 'Total_Purchases', 'Recency']\n",
    "    print(f\"\\nStatical summary:\")\n",
    "    print(df[numerical_cols].describe().round(2))\n",
    "\n",
    "    # Create visualization:\n",
    "    fig, axes = plt.subplots(2, 3, figsize= (15, 10))\n",
    "    fig.suptitle('Distribution Analysis', fontsize = 1)\n",
    "\n",
    "    for i, col in  enumerate(numerical_cols):\n",
    "        row, col_ind = i//3, i%3\n",
    "\n",
    "\n",
    "        # Histrogram:\n",
    "        if row == 0:\n",
    "            axes[row, col_ind].hist(df[col], bins = 20, alpha = 0.7, edgecolor = 'black')\n",
    "            axes[row, col_ind].set_title(f'{col} Distribution')\n",
    "        else:\n",
    "            axes[row, col_ind].boxplot(df[col])\n",
    "            axes[row, col_ind].set_title(f'{col} Box Plot')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task4_distributions.png', dpi = 300, bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Outliner detection and treatement:\n",
    "    numerical_cols = ['Age', 'Income', 'Total_Children','Total_Spending', 'Total_Purchases', 'Recency']\n",
    "    outlier_counts = {}\n",
    "    for col in numerical_cols:\n",
    "        Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]\n",
    "        outlier_counts[col] = f\"{len(outliers)} ({len(outliers) / len(df) * 100:.1f}%)\"\n",
    "\n",
    "    print(f\"\\n Outliners detected: {outlier_counts}\")\n",
    "    \n",
    "    # Outliner Treatement:\n",
    "    for col in ['Age', 'Income']:\n",
    "        Q1, Q3 = df[col].quantile([0.25,0.75])\n",
    "        IQR = Q3- Q1\n",
    "        lower_bound = Q1 - 1 * IQR\n",
    "        upper_bound = Q3 + 1 * IQR\n",
    "\n",
    "        df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "        df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "\n",
    "    print(\"Applied outlier treatement for Age (18-90) and Income (99th percentile cap)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c2784",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task5_categorical_encoding(df):\n",
    "    \"\"\"TAsk 5: Apply ordianl and one-hot encoding.\"\"\"\n",
    "    print(\"\\n \" + \"=\" * 60) \n",
    "    print(\"Task 5: Categorical encoding\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Ordinal encoding:\n",
    "    education_order = ['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']\n",
    "    education_mapping = {\n",
    "        edu: i for i , edu in enumerate(education_order)\n",
    "    }\n",
    "    df_encoded['Education_Ordinal'] = df['Education'].map(education_mapping)\n",
    "\n",
    "    print(f\"Education ordinal encoding: {education_mapping}\")\n",
    "\n",
    "    # One-hot encoding for Marital Status\n",
    "    marital_dummies = pd.get_dummies(df['Marital_Status'], prefix='Marital')\n",
    "    df_encoded = pd.concat([df_encoded, marital_dummies], axis = 1)\n",
    "\n",
    "    print(f\"Marital status One-Hot-Encoded columns: {marital_dummies.columns.tolist()}\")\n",
    "\n",
    "    #Label encoding for Country:\n",
    "\n",
    "    le_country = LabelEncoder()\n",
    "    df_encoded['Country_Encoded'] = le_country.fit_transform(df['Country'])\n",
    "\n",
    "    # Understand this:\n",
    "    print(f\"Country Encoding: {dict(zip(le_country.classes_, range(len(le_country.classes_))))}\")\n",
    "    print(f\"Final Dataset shape: {df_encoded.shape}\")\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f055b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task_6_correlation_analysis(df):\n",
    "    \"\"\"Task 6: Generate Correlation heatmap.\"\"\"\n",
    "    print(\"\\n \" + \"=\" * 60) \n",
    "    print(\"Task 6: Correlation heatmap\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    numerical_cols = [col for col in df.select_dtypes(include = [np.number]).columns if col not in ['Id', 'Year_Birth']]\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "    # Create Heatmap:\n",
    "    plt.figure(figsize=(12,10))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype = bool))\n",
    "    sns.heatmap(correlation_matrix, mask = mask, annot = True, cmap = 'RdYlBu_r', center=0, fmt = '.2f')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task6_correlation_heatmap.png', dpi = 300, bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Find and display strong correlation:\n",
    "    strong_correlation = [(correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i,j])\n",
    "                            for i in range(len(correlation_matrix.columns))\n",
    "                            for j in range(i+1, len(correlation_matrix.columns))\n",
    "                            if abs(correlation_matrix.iloc[i,j]) > 0.7]\n",
    "\n",
    "    print(f\"Strong Correlation (|r| > 0.7): {len(strong_correlation)} found\")\n",
    "    for var1, var2, corr in sorted(strong_correlation, key = lambda x: abs(x[2]), reverse= True):\n",
    "        print(f\" {var1} -> {var2}: {corr:.3f}\")\n",
    "\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c5e3f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task_7_test_hypothesis(df):\n",
    "    \"\"\"Task 7: Test specified hypothesis.\"\"\"\n",
    "    print(\"\\n \" + \"=\" * 60) \n",
    "    print(\"Task 7: Hypothesis Testing\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    median_age = df['Age'].median()\n",
    "\n",
    "    #7.a. Older vs Younger store purchase:\n",
    "    older= df[df['Age']> median_age]['NumStorePurchases']\n",
    "    younger = df[df['Age'] < median_age]['NumStorePurchases']\n",
    "\n",
    "    _,p_val = mannwhitneyu(older, younger, alternative = 'greater')\n",
    "\n",
    "    result = \"Supported\" if p_val < 0.05 else \"Non Supported\"\n",
    "    print(f\"7.a. Older ({older.mean():.1f}) vs Younger ({younger.mean():.1f}) store Purchase: {result}\")\n",
    "\n",
    "    #7b. Children vs no Children web purchase:\n",
    "    with_kids = df[df['Total_Children'] > 0]['NumWebPurchases']\n",
    "    without_kids = df[df['Total_Children'] == 0]['NumWebPurchases']\n",
    "    _,p_val = mannwhitneyu(with_kids, without_kids, alternative = 'greater')\n",
    "\n",
    "    result = \"Supported\" if p_val < 0.05 else \"Non Supported\"\n",
    "    print(f\"7.b. With kid ({with_kids.mean():.1f}) vs No Kids ({without_kids.mean():.1f}) web purchase: {result}\")\n",
    "\n",
    "    # 7.c. Store cannibalization (Negative correlation indicate cannibalization:\n",
    "    \n",
    "    web_corr = df['NumStorePurchases'].corr(df['NumWebPurchases'])\n",
    "    catalog_corr = df['NumStorePurchases'].corr(df['NumCatalogPurchases'])\n",
    "    cannibalization = \"Yes\" if (web_corr < 0 or catalog_corr < 0) else \"No\"\n",
    "    print(f\"7 c. Store Cannibalization: {cannibalization} (web: {web_corr:.3f}, catalog: {catalog_corr:.3f})\")\n",
    "\n",
    "    # 7d. Us vs Non US purchases:\n",
    "    us_purchases = df[df['Country'] == 'US']['Total_Purchases']\n",
    "    no_us_purchases = df[df['Country'] != 'US']['Total_Purchases']\n",
    "    _, p_val = mannwhitneyu(us_purchases, no_us_purchases, alternative= 'greater')\n",
    "    result = \"Supported\" if p_val < 0.05 else \"Not Supported\"\n",
    "    print(f\"7d. Us ({us_purchases.mean():.1f}) vs Non-Us ({no_us_purchases.mean():.1f}) purchases: {result}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0f434",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def task_8_specific_visualization(df):\n",
    "    \"\"\"Task 8: Create Specific Visualization.\"\"\"\n",
    "    print(\"\\n \" + \"=\" * 60) \n",
    "    print(\"Task 8: Specific Visualization\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    fig, axes = plt.subplots(3,2, figsize =(15,18))\n",
    "    fig.suptitle('Specific Business Analysis', fontsize = 14)\n",
    "\n",
    "    # 8.a. Product Performance:\n",
    "    product_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "    \n",
    "    # Calculate total revenue for each Product Category:\n",
    "    product_revenue = {}\n",
    "    for col in product_cols:\n",
    "        product_name = col.replace('Mnt', '')\n",
    "        total_revenue = df[col].sum()\n",
    "        product_revenue[product_name] = total_revenue\n",
    "\n",
    "    # Create bar chart showing revenue of above cols:\n",
    "    product_name = list(product_revenue.keys())\n",
    "    revenue_value = list(product_revenue.values())\n",
    "    axes[0,0].bar(product_name, revenue_value)\n",
    "    axes[0,0].set_title('8a. Product Revenue Performance')\n",
    "    axes[0,0].tick_params(axis = 'x', rotation= 45)\n",
    "\n",
    "    # Find and print top three products by revenue:\n",
    "    sorted_products = sorted(product_revenue.items(), key = lambda x: x[1], reverse = True)\n",
    "    top_3_products = dict(sorted_products[:3])\n",
    "    print(f'Top  Products: {top_3_products}')\n",
    "\n",
    "    # 8.b: Age vs Campaign acceptance\n",
    "    age_bins, age_labels = [18,30,40,50,60,100], ['18-29','30-39', '40-49','50-59','60+']\n",
    "    df['Age_Bin'] = pd.cut(df['Age'], bins = age_bins, labels = age_labels)\n",
    "    age_acceptance = df.groupby('Age_Bin')['Response'].mean() * 100\n",
    "    axes[0,1].bar(range(len(age_acceptance)), age_acceptance.values)\n",
    "    axes[0,1].set_title('8b. Campain Acceptance by Age.')\n",
    "    axes[0,1].set_xticks(range(len(age_acceptance)))\n",
    "    axes[0,1].set_xticklabels(age_acceptance.index)\n",
    "    print(f\"Age acceptance (%): {dict(zip(age_acceptance.index, age_acceptance.values.round(1)))}\")\n",
    "\n",
    "    # 8.c: Country compaign acceptance:\n",
    "    top_countries = df.groupby('Country')['Response'].sum().nlargest(5)\n",
    "    axes[1,0].bar(range(len(top_countries)), top_countries.values)\n",
    "    axes[1,0].set_title('8c. Top countries by campaign acceptance')\n",
    "    axes[1,0].set_xticks(range(len(top_countries)))\n",
    "    axes[1,0].set_xticklabels(top_countries.index)\n",
    "    print(f\"Top countries: {top_countries.to_dict()}\")\n",
    "\n",
    "    # 8d: Chindren vs spending\n",
    "    children_spending = df.groupby('Total_Children')['Total_Spending'].mean()\n",
    "    axes[1,1].plot(children_spending.index, children_spending.values, marker = 'o')\n",
    "    axes[1,1].set_title('8d. Spendings by number of childrens')\n",
    "    axes[1,1].set_xlabel('Number of children')\n",
    "    print(f\"Spending by children: {children_spending.round().to_dict()}\")\n",
    "\n",
    "    # 8e: Education of complainers\n",
    "    complainers = df[df['Complain'] == 1]\n",
    "    if len(complainers) > 0:\n",
    "        complaint_rate = (complainers['Education'].value_counts()/ df['Education'].value_counts() *100).fillna(0)\n",
    "        axes[2,0].bar(range(len(complaint_rate)), complaint_rate.values)\n",
    "        axes[2,0].set_title('8e. Complaint rate by Education.')\n",
    "        axes[2,0].set_xticks(range(len(complaint_rate)))\n",
    "        axes[2,0].set_xticklabels(complaint_rate.index, rotation=45)\n",
    "        print(f\"Complaint rates : {complaint_rate.round(1).to_dict()}\")\n",
    "    else:\n",
    "        axes[2,0].text(0.5,0.5, 'No Complaints', ha = 'center', va = 'center', transform= axes[2,0].transAxes)\n",
    "        print('No Complaints found')\n",
    "\n",
    "    \n",
    "    # Channel preferences by age:\n",
    "    channel_data = df.groupby('Age_Bin')[['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']].mean()\n",
    "    x_pos, width = np.arange(len(age_labels)), 0.25\n",
    "    for i, (channel, label) in enumerate(zip(['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases'],\n",
    "                                             ['Web', 'Catalog', 'Store'])):\n",
    "        axes[2,1].bar(x_pos + i*width - width, channel_data[channel], width, label= label)\n",
    "        axes[2,1].set_title('Channel preferences by Age')\n",
    "        axes[2,1].set_xticks(x_pos)\n",
    "        axes[2,1].set_xticklabels(age_labels)\n",
    "        axes[2,1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task8_specific_visualization.png', dpi = 300, bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"Executing the tasks here.\"\n",
    "    print('Marketing Campaign Data Analysis')\n",
    "\n",
    "    df = task_1_data_import_verification()\n",
    "    df = task_2_missing_data_imputation(df)\n",
    "    df = task_3_feature_engineering(df)\n",
    "    df = task_4_distributed_analysis_outliers(df)\n",
    "    df = task5_categorical_encoding(df)\n",
    "    correlation_metrix = task_6_correlation_analysis(df)\n",
    "    df = task_7_test_hypothesis(df)\n",
    "    df = task_8_specific_visualization(df)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Analysis Completed\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2dc79",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
