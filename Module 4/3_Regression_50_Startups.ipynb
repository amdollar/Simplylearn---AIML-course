{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f1cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93f9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCLRuleMonitor(tf.keras.callbacks.Callback):\n",
    "  def __init__(self,CL):\n",
    "    super(MyCLRuleMonitor,self).__init__()\n",
    "    self.CL = CL\n",
    "\n",
    "\n",
    "  def on_epoch_end(self,epoch,logs=None):\n",
    "    testScore = logs['val_r2_score']\n",
    "    trainScore = logs['r2_score']\n",
    "\n",
    "    if testScore > trainScore and testScore >= self.CL:\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db83d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('50_Startups.csv')\n",
    "# print(data.head())\n",
    "print(data.info())\n",
    "data.dropna(inplace=True)\n",
    "print(data.info())\n",
    "\n",
    "# 1. Features and Labels split\n",
    "features = data.iloc[:, [0,1,2,3]].values\n",
    "labels = data.iloc[:, [4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17a733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "# Transform the State values using One Hot Encoder concat it with the featues and then process\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(features[:,[3]])\n",
    "states = ohe.fit_transform(features[:,[3]])\n",
    "print(states)\n",
    "final_featues = np.concatenate((states, features[:,[0,1,2]]),axis=1)\n",
    "print(final_featues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e59736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "s_features = rs.fit_transform(final_featues)\n",
    "\n",
    "# b. Labels need to be scaled using Min Max Scaler\n",
    "mn = MinMaxScaler()\n",
    "m_labels = mn.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ccbedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(s_features, m_labels, test_size=0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e281e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632ms/step - loss: 0.2784 - r2_score: -4.7224 - val_loss: 0.1569 - val_r2_score: -1.7275\n",
      "Epoch 2/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.1431 - r2_score: -1.9419 - val_loss: 0.0806 - val_r2_score: -0.4009\n",
      "Epoch 3/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0761 - r2_score: -0.5643 - val_loss: 0.0503 - val_r2_score: 0.1252\n",
      "Epoch 4/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0485 - r2_score: 0.0035 - val_loss: 0.0415 - val_r2_score: 0.2785\n",
      "Epoch 5/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0445 - r2_score: 0.0846 - val_loss: 0.0335 - val_r2_score: 0.4174\n",
      "Epoch 6/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.0392 - r2_score: 0.1941 - val_loss: 0.0200 - val_r2_score: 0.6524\n",
      "Epoch 7/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - loss: 0.0285 - r2_score: 0.4144 - val_loss: 0.0107 - val_r2_score: 0.8137\n",
      "Epoch 8/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.0172 - r2_score: 0.6455 - val_loss: 0.0088 - val_r2_score: 0.8464\n",
      "Epoch 9/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0126 - r2_score: 0.7401 - val_loss: 0.0118 - val_r2_score: 0.7946\n",
      "Epoch 10/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0120 - r2_score: 0.7535 - val_loss: 0.0143 - val_r2_score: 0.7513\n",
      "Epoch 11/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0128 - r2_score: 0.7362 - val_loss: 0.0133 - val_r2_score: 0.7689\n",
      "Epoch 12/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0113 - r2_score: 0.7673 - val_loss: 0.0093 - val_r2_score: 0.8376\n",
      "Epoch 13/100000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0079 - r2_score: 0.8379 - val_loss: 0.0060 - val_r2_score: 0.8957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24638862fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deep learning model steps:\n",
    "# 1. Model architeching (Creating Input/Hidden and Output layers)\n",
    "# 2. Model compile\n",
    "# 3. Model fit (Training)\n",
    "# 4. Model evaluation\n",
    "# 5. Model deployment\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "# Model architecting:\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 100, activation='relu', input_shape=(6,)))\n",
    "# Handle the no of feature cols and activation function as per rules.\n",
    "model.add(tf.keras.layers.Dense(units= 100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units= 100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units= 1, activation='linear'))\n",
    "\n",
    "# 2. Model compile:\n",
    "model.compile(optimizer = 'adam',loss = 'mean_squared_error' ,metrics = [tf.keras.metrics.R2Score()])\n",
    "\n",
    "\n",
    "# 3. Fit the model/ Train\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs= 100000 ,callbacks=[MyCLRuleMonitor(.85)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model evaluation\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_r2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test R2 Score: {test_r2:.4f}')\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_r2 = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train R2 Score: {train_r2:.4f}')\n",
    "\n",
    "# Optional: Save the model for future use\n",
    "# model.save('50_Startups_Profit_Predictor.keras')\n",
    "# model.save('50_Startups_Profit_Predictor.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "For values: 1000.0,2322.0, 4433.0, and New York: Expected profit is: [[38238.273]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing app: Reading inputs\n",
    "rdspends = float(input('Enter the r&d spends: '))\n",
    "adminspends = float(input('Enter the admin spends: '))\n",
    "marketingspends = float(input('Enter the marketing spends: '))\n",
    "state = input('Enter the location: ')\n",
    "\n",
    "# Encode the state value:\n",
    "state_values = ohe.categories_[0]\n",
    "while state not in state_values:\n",
    "   state = input('Enter the location: ')\n",
    "\n",
    "# Transform this value:\n",
    "input_state = ohe.transform(np.array([[state]]))\n",
    "input_final_features = np.concatenate((input_state, np.array([[rdspends, adminspends, marketingspends]])), axis = 1)\n",
    "\n",
    "# Scale the features (use transform, not fit_transform, to use the scaler fitted on training data):\n",
    "scaled_input = rs.transform(input_final_features)\n",
    "predicted_values = model.predict(scaled_input)\n",
    "\n",
    "# reverse transform the predicted value:\n",
    "profit  = mn.inverse_transform(predicted_values)\n",
    "\n",
    "print(f'For values: {rdspends},{adminspends}, {marketingspends}, and {state}: Expected profit is: {profit}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74def8",
   "metadata": {},
   "source": [
    "# ğŸ“Š Model Evaluation Techniques Guide\n",
    "\n",
    "## When to Use What Evaluation Metric?\n",
    "\n",
    "This guide covers all evaluation techniques for both **Classification** and **Regression** problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c81a28",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Comparison Table: Evaluation Metrics\n",
    "\n",
    "| Metric | Problem Type | Range | Best Value | When to Use | Sensitive To |\n",
    "|--------|-------------|-------|------------|-------------|--------------|\n",
    "| **Accuracy** | Classification | 0-1 | 1.0 | Balanced datasets, equal class importance | Class imbalance |\n",
    "| **Precision** | Classification | 0-1 | 1.0 | When False Positives are costly (spam detection, fraud) | Class imbalance |\n",
    "| **Recall (Sensitivity)** | Classification | 0-1 | 1.0 | When False Negatives are costly (disease detection, security) | Class imbalance |\n",
    "| **F1-Score** | Classification | 0-1 | 1.0 | Need balance between Precision & Recall, imbalanced data | - |\n",
    "| **ROC-AUC** | Binary Classification | 0-1 | 1.0 | Need threshold-independent metric, compare models | Class imbalance |\n",
    "| **Confusion Matrix** | Classification | - | - | Understand error types, visualize performance | - |\n",
    "| **MSE** | Regression | 0-âˆ | 0 | Penalize large errors heavily, same units as squared target | Outliers |\n",
    "| **RMSE** | Regression | 0-âˆ | 0 | Same units as target, interpretable, penalize large errors | Outliers |\n",
    "| **MAE** | Regression | 0-âˆ | 0 | Robust to outliers, interpretable, same units as target | - |\n",
    "| **RÂ² Score** | Regression | -âˆ to 1 | 1.0 | Overall model fit, percentage of variance explained | - |\n",
    "| **MAPE** | Regression | 0-âˆ | 0 | Percentage errors, scale-independent, business-friendly | Zero values |\n",
    "| **Adjusted RÂ²** | Regression | -âˆ to 1 | 1.0 | Multiple features, penalizes unnecessary features | - |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# REGRESSION EVALUATION METRICS - EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data for regression\n",
    "y_true_reg = np.array([100, 200, 300, 400, 500])\n",
    "y_pred_reg = np.array([110, 190, 310, 390, 510])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REGRESSION EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True values: {y_true_reg}\")\n",
    "print(f\"Predicted values: {y_pred_reg}\\n\")\n",
    "\n",
    "# 1. Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "print(f\"1. MSE (Mean Squared Error): {mse:.2f}\")\n",
    "print(\"   â†’ Use when: You want to penalize large errors heavily\")\n",
    "print(\"   â†’ Best for: Models where large errors are unacceptable\")\n",
    "print(\"   â†’ Range: 0 to âˆ (lower is better)\\n\")\n",
    "\n",
    "# 2. Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"2. RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(\"   â†’ Use when: You want interpretable errors in same units as target\")\n",
    "print(\"   â†’ Best for: General regression problems, easy to explain\")\n",
    "print(\"   â†’ Range: 0 to âˆ (lower is better)\\n\")\n",
    "\n",
    "# 3. Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "print(f\"3. MAE (Mean Absolute Error): {mae:.2f}\")\n",
    "print(\"   â†’ Use when: You want robustness to outliers\")\n",
    "print(\"   â†’ Best for: When outliers are present, interpretable errors\")\n",
    "print(\"   â†’ Range: 0 to âˆ (lower is better)\\n\")\n",
    "\n",
    "# 4. RÂ² Score (Coefficient of Determination)\n",
    "r2 = r2_score(y_true_reg, y_pred_reg)\n",
    "print(f\"4. RÂ² Score: {r2:.4f}\")\n",
    "print(\"   â†’ Use when: You want to know % of variance explained\")\n",
    "print(\"   â†’ Best for: Overall model quality assessment\")\n",
    "print(\"   â†’ Range: -âˆ to 1 (1.0 = perfect, 0 = baseline, negative = worse than baseline)\\n\")\n",
    "\n",
    "# 5. Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_percentage_error(y_true_reg, y_pred_reg) * 100\n",
    "print(f\"5. MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "print(\"   â†’ Use when: You need percentage-based errors for business\")\n",
    "print(\"   â†’ Best for: Business reporting, scale-independent comparison\")\n",
    "print(\"   â†’ Range: 0 to âˆ% (lower is better)\\n\")\n",
    "\n",
    "# 6. Adjusted RÂ² (for multiple features)\n",
    "# Formula: 1 - [(1-RÂ²)(n-1)/(n-k-1)] where n=samples, k=features\n",
    "n = len(y_true_reg)\n",
    "k = 1  # number of features (example)\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "print(f\"6. Adjusted RÂ²: {adj_r2:.4f}\")\n",
    "print(\"   â†’ Use when: Comparing models with different numbers of features\")\n",
    "print(\"   â†’ Best for: Multiple regression, feature selection\")\n",
    "print(\"   â†’ Range: -âˆ to 1 (penalizes unnecessary features)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011154f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CLASSIFICATION EVALUATION METRICS - EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            classification_report, roc_curve)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Sample data for binary classification\n",
    "y_true_binary = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 1])\n",
    "y_pred_binary = np.array([0, 1, 1, 0, 0, 0, 1, 1, 1, 1])\n",
    "y_proba_binary = np.array([0.1, 0.9, 0.8, 0.2, 0.4, 0.3, 0.6, 0.85, 0.95, 0.9])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BINARY CLASSIFICATION EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True labels: {y_true_binary}\")\n",
    "print(f\"Predicted labels: {y_pred_binary}\")\n",
    "print(f\"Predicted probabilities: {y_proba_binary}\\n\")\n",
    "\n",
    "# 1. Accuracy\n",
    "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "print(f\"1. Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(\"   â†’ Use when: Classes are balanced, all errors are equally important\")\n",
    "print(\"   â†’ Best for: Balanced datasets, general performance measure\")\n",
    "print(\"   â†’ Range: 0 to 1 (higher is better)\\n\")\n",
    "\n",
    "# 2. Precision\n",
    "precision = precision_score(y_true_binary, y_pred_binary)\n",
    "print(f\"2. Precision: {precision:.4f}\")\n",
    "print(\"   â†’ Use when: False Positives are costly (spam detection, fraud)\")\n",
    "print(\"   â†’ Best for: When you can't afford false alarms\")\n",
    "print(\"   â†’ Range: 0 to 1 (higher is better)\\n\")\n",
    "\n",
    "# 3. Recall (Sensitivity)\n",
    "recall = recall_score(y_true_binary, y_pred_binary)\n",
    "print(f\"3. Recall (Sensitivity): {recall:.4f}\")\n",
    "print(\"   â†’ Use when: False Negatives are costly (disease detection, security)\")\n",
    "print(\"   â†’ Best for: When you can't afford to miss positive cases\")\n",
    "print(\"   â†’ Range: 0 to 1 (higher is better)\\n\")\n",
    "\n",
    "# 4. F1-Score\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "print(f\"4. F1-Score: {f1:.4f}\")\n",
    "print(\"   â†’ Use when: Need balance between Precision & Recall\")\n",
    "print(\"   â†’ Best for: Imbalanced datasets, harmonic mean of P & R\")\n",
    "print(\"   â†’ Range: 0 to 1 (higher is better)\\n\")\n",
    "\n",
    "# 5. ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_true_binary, y_proba_binary)\n",
    "print(f\"5. ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"   â†’ Use when: Need threshold-independent metric\")\n",
    "print(\"   â†’ Best for: Comparing models, class imbalance\")\n",
    "print(\"   â†’ Range: 0 to 1 (1.0 = perfect, 0.5 = random)\\n\")\n",
    "\n",
    "# 6. Confusion Matrix\n",
    "cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "print(f\"6. Confusion Matrix:\")\n",
    "print(f\"   {cm}\")\n",
    "print(\"   â†’ Use when: You need to understand error types\")\n",
    "print(\"   â†’ Best for: Visualizing TP, TN, FP, FN\")\n",
    "print(\"   â†’ Format: [[TN, FP], [FN, TP]]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MULTICLASS CLASSIFICATION - EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "# Sample data for multiclass classification (3 classes: 0, 1, 2)\n",
    "y_true_multi = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
    "y_pred_multi = np.array([0, 1, 2, 0, 1, 1, 0, 2, 2])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTICLASS CLASSIFICATION EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True labels: {y_true_multi}\")\n",
    "print(f\"Predicted labels: {y_pred_multi}\\n\")\n",
    "\n",
    "# For multiclass, we can use different averaging strategies\n",
    "print(\"1. Accuracy (Multiclass):\")\n",
    "acc_multi = accuracy_score(y_true_multi, y_pred_multi)\n",
    "print(f\"   Accuracy: {acc_multi:.4f}\\n\")\n",
    "\n",
    "print(\"2. Precision (Multiclass - Macro Average):\")\n",
    "prec_macro = precision_score(y_true_multi, y_pred_multi, average='macro')\n",
    "print(f\"   Macro Precision: {prec_macro:.4f}\")\n",
    "print(\"   â†’ Average of precision for each class (equal weight)\\n\")\n",
    "\n",
    "print(\"3. Precision (Multiclass - Weighted Average):\")\n",
    "prec_weighted = precision_score(y_true_multi, y_pred_multi, average='weighted')\n",
    "print(f\"   Weighted Precision: {prec_weighted:.4f}\")\n",
    "print(\"   â†’ Weighted by number of samples per class\\n\")\n",
    "\n",
    "print(\"4. Recall (Multiclass - Macro Average):\")\n",
    "recall_macro = recall_score(y_true_multi, y_pred_multi, average='macro')\n",
    "print(f\"   Macro Recall: {recall_macro:.4f}\\n\")\n",
    "\n",
    "print(\"5. F1-Score (Multiclass - Macro Average):\")\n",
    "f1_macro = f1_score(y_true_multi, y_pred_multi, average='macro')\n",
    "print(f\"   Macro F1: {f1_macro:.4f}\\n\")\n",
    "\n",
    "print(\"6. Classification Report:\")\n",
    "print(classification_report(y_true_multi, y_pred_multi))\n",
    "print(\"   â†’ Provides precision, recall, F1 for each class\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5837755",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Decision Guide\n",
    "\n",
    "### For REGRESSION Problems:\n",
    "\n",
    "**Use MSE/RMSE when:**\n",
    "- You want to penalize large errors heavily\n",
    "- Same units as target variable needed\n",
    "- Example: House price prediction, stock price prediction\n",
    "\n",
    "**Use MAE when:**\n",
    "- You have outliers in your data\n",
    "- You want interpretable errors\n",
    "- Example: Salary prediction with some extreme values\n",
    "\n",
    "**Use RÂ² when:**\n",
    "- You want to know overall model quality\n",
    "- You need to compare different models\n",
    "- Example: Comparing multiple regression models\n",
    "\n",
    "**Use MAPE when:**\n",
    "- You need percentage-based errors\n",
    "- Business stakeholders need easy interpretation\n",
    "- Example: Sales forecasting, revenue prediction\n",
    "\n",
    "### For CLASSIFICATION Problems:\n",
    "\n",
    "**Use Accuracy when:**\n",
    "- Classes are balanced\n",
    "- All errors are equally important\n",
    "- Example: Balanced email classification\n",
    "\n",
    "**Use Precision when:**\n",
    "- False Positives are costly\n",
    "- Example: Spam detection (don't want to mark important emails as spam)\n",
    "\n",
    "**Use Recall when:**\n",
    "- False Negatives are costly\n",
    "- Example: Disease detection (don't want to miss a disease)\n",
    "\n",
    "**Use F1-Score when:**\n",
    "- You need balance between Precision & Recall\n",
    "- Classes are imbalanced\n",
    "- Example: Fraud detection, medical diagnosis\n",
    "\n",
    "**Use ROC-AUC when:**\n",
    "- You want threshold-independent metric\n",
    "- You need to compare multiple models\n",
    "- Example: Model selection, binary classification with imbalanced data\n",
    "\n",
    "**Use Confusion Matrix when:**\n",
    "- You need to understand error types\n",
    "- You want to visualize performance\n",
    "- Example: Understanding where model fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# REAL-WORLD USE CASE EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REAL-WORLD USE CASE EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“Š REGRESSION USE CASES:\\n\")\n",
    "\n",
    "print(\"1. HOUSE PRICE PREDICTION\")\n",
    "print(\"   â†’ Use: RMSE or MAE\")\n",
    "print(\"   â†’ Why: Easy to interpret (dollars), penalize large errors\")\n",
    "print(\"   â†’ Example: 'Average prediction error is $50,000'\\n\")\n",
    "\n",
    "print(\"2. SALARY PREDICTION\")\n",
    "print(\"   â†’ Use: MAE or RÂ²\")\n",
    "print(\"   â†’ Why: Robust to outliers, overall model quality\")\n",
    "print(\"   â†’ Example: 'Model explains 85% of salary variance'\\n\")\n",
    "\n",
    "print(\"3. SALES FORECASTING\")\n",
    "print(\"   â†’ Use: MAPE\")\n",
    "print(\"   â†’ Why: Business-friendly percentage errors\")\n",
    "print(\"   â†’ Example: 'Average error is 12% of actual sales'\\n\")\n",
    "\n",
    "print(\"4. STOCK PRICE PREDICTION\")\n",
    "print(\"   â†’ Use: RMSE or MAE\")\n",
    "print(\"   â†’ Why: Same units, interpretable\")\n",
    "print(\"   â†’ Example: 'Average error is $2.50 per share'\\n\")\n",
    "\n",
    "print(\"\\nğŸ¯ CLASSIFICATION USE CASES:\\n\")\n",
    "\n",
    "print(\"1. SPAM EMAIL DETECTION\")\n",
    "print(\"   â†’ Use: Precision (or F1-Score)\")\n",
    "print(\"   â†’ Why: Can't mark important emails as spam (False Positives costly)\")\n",
    "print(\"   â†’ Example: '99% of emails marked as spam are actually spam'\\n\")\n",
    "\n",
    "print(\"2. DISEASE DETECTION (Medical)\")\n",
    "print(\"   â†’ Use: Recall (or F1-Score)\")\n",
    "print(\"   â†’ Why: Can't miss detecting a disease (False Negatives costly)\")\n",
    "print(\"   â†’ Example: 'Detects 95% of all actual diseases'\\n\")\n",
    "\n",
    "print(\"3. FRAUD DETECTION\")\n",
    "print(\"   â†’ Use: F1-Score or ROC-AUC\")\n",
    "print(\"   â†’ Why: Need balance, imbalanced data (few fraud cases)\")\n",
    "print(\"   â†’ Example: 'Balanced performance on both precision and recall'\\n\")\n",
    "\n",
    "print(\"4. CUSTOMER CHURN PREDICTION\")\n",
    "print(\"   â†’ Use: F1-Score or ROC-AUC\")\n",
    "print(\"   â†’ Why: Imbalanced data, need balance\")\n",
    "print(\"   â†’ Example: 'Good at identifying customers who will churn'\\n\")\n",
    "\n",
    "print(\"5. IMAGE CLASSIFICATION (Multiclass)\")\n",
    "print(\"   â†’ Use: Accuracy or Macro F1-Score\")\n",
    "print(\"   â†’ Why: Multiple classes, need overall performance\")\n",
    "print(\"   â†’ Example: 'Correctly classifies 92% of images'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TENSORFLOW/KERAS EVALUATION METRICS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TENSORFLOW/KERAS EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nFor REGRESSION in TensorFlow/Keras:\\n\")\n",
    "print(\"Available metrics:\")\n",
    "print(\"  - 'mse' or tf.keras.metrics.MeanSquaredError()\")\n",
    "print(\"  - 'mae' or tf.keras.metrics.MeanAbsoluteError()\")\n",
    "print(\"  - 'rmse' (custom) or tf.keras.metrics.RootMeanSquaredError()\")\n",
    "print(\"  - tf.keras.metrics.R2Score()\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"  model.compile(optimizer='adam',\")\n",
    "print(\"                loss='mean_squared_error',\")\n",
    "print(\"                metrics=[tf.keras.metrics.R2Score(),\")\n",
    "print(\"                         tf.keras.metrics.MeanAbsoluteError()])\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nFor CLASSIFICATION in TensorFlow/Keras:\\n\")\n",
    "print(\"Available metrics:\")\n",
    "print(\"  - 'accuracy' or tf.keras.metrics.Accuracy()\")\n",
    "print(\"  - 'precision' or tf.keras.metrics.Precision()\")\n",
    "print(\"  - 'recall' or tf.keras.metrics.Recall()\")\n",
    "print(\"  - tf.keras.metrics.AUC()\")\n",
    "print(\"  - tf.keras.metrics.F1Score()\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"  model.compile(optimizer='adam',\")\n",
    "print(\"                loss='binary_crossentropy',\")\n",
    "print(\"                metrics=['accuracy',\")\n",
    "print(\"                         tf.keras.metrics.Precision(),\")\n",
    "print(\"                         tf.keras.metrics.Recall(),\")\n",
    "print(\"                         tf.keras.metrics.AUC()])\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nğŸ’¡ TIP: Use model.evaluate() to get metrics on test data\")\n",
    "print(\"   Example: loss, accuracy = model.evaluate(X_test, y_test)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2810d92",
   "metadata": {},
   "source": [
    "## ğŸ”€ Decision Flowchart\n",
    "\n",
    "### REGRESSION Metrics Decision Tree:\n",
    "\n",
    "```\n",
    "Is your target variable continuous/numeric?\n",
    "    â”‚\n",
    "    â”œâ”€ YES â†’ REGRESSION\n",
    "    â”‚   â”‚\n",
    "    â”‚   â”œâ”€ Need percentage errors for business?\n",
    "    â”‚   â”‚   â”œâ”€ YES â†’ Use MAPE\n",
    "    â”‚   â”‚   â””â”€ NO â†’ Continue...\n",
    "    â”‚   â”‚\n",
    "    â”‚   â”œâ”€ Have outliers in data?\n",
    "    â”‚   â”‚   â”œâ”€ YES â†’ Use MAE (robust to outliers)\n",
    "    â”‚   â”‚   â””â”€ NO â†’ Continue...\n",
    "    â”‚   â”‚\n",
    "    â”‚   â”œâ”€ Need to penalize large errors heavily?\n",
    "    â”‚   â”‚   â”œâ”€ YES â†’ Use RMSE or MSE\n",
    "    â”‚   â”‚   â””â”€ NO â†’ Use MAE\n",
    "    â”‚   â”‚\n",
    "    â”‚   â””â”€ Need overall model quality assessment?\n",
    "    â”‚       â””â”€ YES â†’ Use RÂ² Score\n",
    "```\n",
    "\n",
    "### CLASSIFICATION Metrics Decision Tree:\n",
    "\n",
    "```\n",
    "Is your target variable categorical?\n",
    "    â”‚\n",
    "    â”œâ”€ YES â†’ CLASSIFICATION\n",
    "    â”‚   â”‚\n",
    "    â”‚   â”œâ”€ How many classes?\n",
    "    â”‚   â”‚   â”œâ”€ 2 classes â†’ BINARY CLASSIFICATION\n",
    "    â”‚   â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â”‚   â”œâ”€ Classes balanced?\n",
    "    â”‚   â”‚   â”‚   â”‚   â”œâ”€ YES â†’ Use Accuracy\n",
    "    â”‚   â”‚   â”‚   â”‚   â””â”€ NO â†’ Continue...\n",
    "    â”‚   â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â”‚   â”œâ”€ False Positives costly? (spam, fraud alerts)\n",
    "    â”‚   â”‚   â”‚   â”‚   â””â”€ YES â†’ Use Precision\n",
    "    â”‚   â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â”‚   â”œâ”€ False Negatives costly? (disease, security)\n",
    "    â”‚   â”‚   â”‚   â”‚   â””â”€ YES â†’ Use Recall\n",
    "    â”‚   â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â”‚   â”œâ”€ Need balance between P & R?\n",
    "    â”‚   â”‚   â”‚   â”‚   â””â”€ YES â†’ Use F1-Score\n",
    "    â”‚   â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â”‚   â””â”€ Need threshold-independent metric?\n",
    "    â”‚   â”‚   â”‚       â””â”€ YES â†’ Use ROC-AUC\n",
    "    â”‚   â”‚   â”‚\n",
    "    â”‚   â”‚   â””â”€ 3+ classes â†’ MULTICLASS CLASSIFICATION\n",
    "    â”‚   â”‚       â”‚\n",
    "    â”‚   â”‚       â”œâ”€ Classes balanced?\n",
    "    â”‚   â”‚       â”‚   â”œâ”€ YES â†’ Use Accuracy or Macro F1\n",
    "    â”‚   â”‚       â”‚   â””â”€ NO â†’ Use Weighted F1 or Macro F1\n",
    "    â”‚   â”‚       â”‚\n",
    "    â”‚   â”‚       â””â”€ Need per-class metrics?\n",
    "    â”‚   â”‚           â””â”€ YES â†’ Use Classification Report\n",
    "```\n",
    "\n",
    "## ğŸ“ Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. **Regression**: Use RMSE/MAE for interpretability, RÂ² for overall quality, MAPE for business reporting\n",
    "2. **Binary Classification**: Use Precision when FP costly, Recall when FN costly, F1 for balance, ROC-AUC for comparison\n",
    "3. **Multiclass**: Use Accuracy for balanced, Macro/Weighted F1 for imbalanced\n",
    "4. **Always consider**: Class imbalance, cost of errors, business requirements\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
