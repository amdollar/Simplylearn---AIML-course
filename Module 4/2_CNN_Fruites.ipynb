{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274aed77",
   "metadata": {},
   "source": [
    "Extract the zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2c8e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCLRuleMonitor(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, CL):\n",
    "    super(MyCLRuleMonitor).__init__()\n",
    "    self.CL = CL\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    trainScore = logs[\"accuracy\"]\n",
    "    testScore = logs[\"val_accuracy\"]\n",
    "\n",
    "    if testScore > trainScore and testScore >= self.CL:\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dcad541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extacted the file\n"
     ]
    }
   ],
   "source": [
    "zip_name = 'fruits-small.zip'\n",
    "extracted_file = 'fruits-small'\n",
    "\n",
    "# Make new directory:\n",
    "os.makedirs(extracted_file, exist_ok = True)\n",
    "\n",
    "try:\n",
    "    shutil.unpack_archive(filename= zip_name, extract_dir= extracted_file)\n",
    "    print('Successfully extacted the file')\n",
    "except Exception as e:\n",
    "    print('Error while unpacking the zip file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1cf49",
   "metadata": {},
   "source": [
    "Steps for Model creation:\n",
    "0. Data Preprocessing\n",
    "    i. Image Generators\n",
    "    ii. Splitting Train and Test data from Generators\n",
    "1. Model architecting + Prepro\n",
    "    i. CNN + ANN layers creation\n",
    "2. Model Compilation\n",
    "3. Model Training \n",
    "4. Model Evaluation\n",
    "5. Model Testing / Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7915df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data compatible using ImageDataGenerators:\n",
    "# Each image in the Folders will be normalized using rescale.\n",
    "train_image_generator= tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0)\n",
    "test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a57130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3425 images belonging to 7 classes.\n",
      "Found 1150 images belonging to 7 classes.\n",
      "Found 1150 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Splitting Test and Train Data:\n",
    "\n",
    "train_image_data = train_image_generator.flow_from_directory('fruits-small/fruits-small/data/Training',\n",
    "                                                             batch_size= 3,\n",
    "                                                             class_mode = 'categorical',\n",
    "                                                             target_size = (224,224))\n",
    "\n",
    "\n",
    "test_image_data = test_image_generator.flow_from_directory('fruits-small/fruits-small/data/Validation',\n",
    "                                                           batch_size= 3,\n",
    "                                                           class_mode = 'categorical',\n",
    "                                                           target_size= (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3733e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_data.image_shape\n",
    "test_image_data.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3cd0c725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,932,583</span> (98.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,932,583\u001b[0m (98.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,932,583</span> (98.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,932,583\u001b[0m (98.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Architecting:\n",
    "# CNN: A Convolution layer is combination of Convolve and Pooling:\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Conv2d(noofFeatureMaps, kernelShape, inputShape, activation) + padding = same -- add virtual boarder in every image\n",
    "# NoOfFeatureMaps: Similar to no of units: Based on trial and error\n",
    "# filter: (3,3), (4,4), (5,5) common :  in this content will be initialized randomly\n",
    "# inputShape: similar to target_size\n",
    "\n",
    "# ----------------- 1st convole layer:\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), input_shape= train_image_data.image_shape, activation='relu', padding= 'same'))\n",
    "# Adding Pooling:\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# ------------------- 2nd Convole layer:\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding= 'same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# -------------------- Flatten:\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# FC Layer | ANN part, Layers creation:\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units= 256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units= 512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units= 128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units= 256, activation= 'relu'))\n",
    "\n",
    "# Output layer:\n",
    "model.add(tf.keras.layers.Dense(units = 7, activation='softmax'))\n",
    "\n",
    "# Model Summay:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab877155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmpilation:\n",
    "# Balanced dat is there\n",
    "# A balanced dataset, in the context of machine learning classification tasks, is a dataset in which every class or category is represented by an approximately equal number of samples. \n",
    "model.compile(optimizer= 'adam',\n",
    "              loss= 'categorical_crossentropy',\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9f82b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 440ms/step - accuracy: 0.8942 - loss: 0.3822 - val_accuracy: 0.8503 - val_loss: 0.4323\n",
      "Epoch 2/100\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 440ms/step - accuracy: 0.8942 - loss: 0.3822 - val_accuracy: 0.8503 - val_loss: 0.4323\n",
      "Epoch 2/100\n",
      "\u001b[1m   1/1141\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:05\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thedo\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8486 - val_loss: 0.4079\n",
      "Epoch 3/100\n",
      "Epoch 3/100\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 438ms/step - accuracy: 0.9670 - loss: 0.2270 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 438ms/step - accuracy: 0.9670 - loss: 0.2270 - val_accuracy: 1.0000 - val_loss: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2292c962f50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training:\n",
    "\n",
    "model.fit(train_image_data, \n",
    "          validation_data = test_image_data, \n",
    "          epochs = 100, \n",
    "          steps_per_epoch = (len(train_image_data.filenames)//train_image_data.batch_size ),\n",
    "          validation_steps= (len(test_image_data.filenames)//test_image_data.batch_size),\n",
    "          callbacks = MyCLRuleMonitor(0.9))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "668b3aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "0\n",
      "['Banana', 'Lemon', 'Mango', 'Orange', 'Pineapple', 'Pomegranate', 'Strawberry']\n",
      "Banana\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "0\n",
      "['Banana', 'Lemon', 'Mango', 'Orange', 'Pineapple', 'Pomegranate', 'Strawberry']\n",
      "Banana\n"
     ]
    }
   ],
   "source": [
    "# Input / Deployment / Testing:\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img('fazli-mango.jpg', target_size = (224,224))\n",
    "image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "image_np_array = np.expand_dims(image_array, axis = 0)\n",
    "prediction_probabilities = model.predict(image_np_array)\n",
    "\n",
    "train_dir = 'fruits-small/fruits-small/data/Training'\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "\n",
    "prediction_class_index= np.argmax(prediction_probabilities)\n",
    "prediction_class_name = class_names[prediction_class_index]\n",
    "print(prediction_class_index)\n",
    "print(class_names)\n",
    "print(prediction_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd598fc1",
   "metadata": {},
   "source": [
    "It is not able to predict a Mango and giving res as Banana, So WIll be playing with the batch size and let it run again, then we will try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c389f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ec126c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
