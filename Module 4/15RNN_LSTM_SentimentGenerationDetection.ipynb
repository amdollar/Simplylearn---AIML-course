{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e478ca5",
   "metadata": {},
   "source": [
    "This model will read data from a large set and Classify the Sentiment:\n",
    "Positive, Negative, Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7308c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('swiggy.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d381f257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  1,  2,  3],\n",
       "       [ 7,  4,  1,  2,  8],\n",
       "       [ 3,  4,  9, 10,  0]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small code snippet for Tokenizer:\n",
    "\n",
    "sentences = [\n",
    "    'I am a good Boy', \n",
    "    'This is a good desk',\n",
    "    'Boy is roaming around'\n",
    "]\n",
    "\n",
    "# Build vocab from the text data:\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# View the word index (Vocab index)\n",
    "word_index = tokenizer.word_index\n",
    "word_index\n",
    "\n",
    "# Convert orignal text to sequence\n",
    "text_to_sequence = tokenizer.texts_to_sequences(sentences)\n",
    "text_to_sequence\n",
    "\n",
    "# pad_sequences: This function ensures that all sequences in a list have the same length, \n",
    "# which is a requirement for feeding data into a neural network.\n",
    "padded_sequence = pad_sequences(text_to_sequence, padding = 'post')\n",
    "padded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95373401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Area</th>\n",
       "      <th>City</th>\n",
       "      <th>Restaurant Price</th>\n",
       "      <th>Avg Rating</th>\n",
       "      <th>Total Rating</th>\n",
       "      <th>Food Item</th>\n",
       "      <th>Food Type</th>\n",
       "      <th>Delivery Time</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Suburb</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>600</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6198</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>30-40 min</td>\n",
       "      <td>Good, but nothing extraordinary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Business District</td>\n",
       "      <td>Pune</td>\n",
       "      <td>200</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4865</td>\n",
       "      <td>Pepperoni Pizza</td>\n",
       "      <td>Non-Vegetarian</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>Good, but nothing extraordinary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Suburb</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>600</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2095</td>\n",
       "      <td>Waffles</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>Late delivery ruined it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Business District</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6639</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>Best meal I've had in a while!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tech Park</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>200</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6926</td>\n",
       "      <td>Spring Rolls</td>\n",
       "      <td>Gluten-Free</td>\n",
       "      <td>20-30 min</td>\n",
       "      <td>Mediocre experience.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID               Area       City  Restaurant Price  Avg Rating  \\\n",
       "0   1             Suburb  Ahmedabad               600         4.2   \n",
       "1   2  Business District       Pune               200         4.7   \n",
       "2   3             Suburb  Bangalore               600         4.7   \n",
       "3   4  Business District     Mumbai               900         4.0   \n",
       "4   5          Tech Park     Mumbai               200         4.7   \n",
       "\n",
       "   Total Rating        Food Item       Food Type Delivery Time  \\\n",
       "0          6198            Sushi       Fast Food     30-40 min   \n",
       "1          4865  Pepperoni Pizza  Non-Vegetarian     50-60 min   \n",
       "2          2095          Waffles       Fast Food     50-60 min   \n",
       "3          6639            Sushi      Vegetarian     50-60 min   \n",
       "4          6926     Spring Rolls     Gluten-Free     20-30 min   \n",
       "\n",
       "                             Review  \n",
       "0  Good, but nothing extraordinary.  \n",
       "1  Good, but nothing extraordinary.  \n",
       "2          Late delivery ruined it.  \n",
       "3    Best meal I've had in a while!  \n",
       "4              Mediocre experience.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('swiggy.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11587a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing:\n",
    "# Cleaning and sentiment labeling:\n",
    "\n",
    "data['Review'] = data['Review'].str.lower()\n",
    "data['Review']\n",
    "\n",
    "# good, but nothing extraordinary.\n",
    "# Data still has many non-needed values we need to clear it:\n",
    "\n",
    "data['Review'] = data['Review'].replace(r'[^a-z0-9\\s]', '', regex = True)\n",
    "data['Review']\n",
    "# good but nothing extraordinary\n",
    "\n",
    "# Sentiment col adding 1 for > 3.5 and 0 otherwise\n",
    "data['Sentiment'] = data['Avg Rating'].apply(lambda x: 1 if x > 3.5 else 0)\n",
    "data['Sentiment']\n",
    "\n",
    "# Drop the null rows:\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688aa60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and pad the review data and extract the target sentiment:\n",
    "# Tokenize: Helps to convert text data to inter sequence\n",
    "# Padding: Makes sure all the input sequences are of same length.\n",
    "\n",
    "\n",
    "max_features = 5000 #Sets the maximum number of words to keep in the tokenizer\n",
    "max_length = 200 # Defines the fixed length for each input sequence after padding\n",
    "tokenizer = Tokenizer(num_words= max_features)\n",
    "tokenizer.fit_on_texts(data['Review'])\n",
    "text_to_sequence= tokenizer.texts_to_sequences(data['Review'])\n",
    "\n",
    "\n",
    "# [47, 10, 11, 48],\n",
    "#  [47, 10, 11, 48],\n",
    "#  [71, 9, 72, 3],\n",
    "\n",
    "X = pad_sequences(text_to_sequence, maxlen = max_length)\n",
    "y = data['Sentiment'].values\n",
    "\n",
    "\n",
    "X #[[ 0,  0,  0, ..., 10, 11, 48],\n",
    "    #    [ 0,  0,  0, ..., 10, 11, 48],\n",
    "\n",
    "y  #[1, 1, 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data: Training, validation and test sets\n",
    "# While mainting the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6156eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stratify parameter in scikit-learn's train_test_split function ensures that the resulting training and testing sets maintain \n",
    "# the same proportion of samples for each class as in the original dataset. \n",
    "\n",
    "\n",
    "# train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) : Splits data into 80% training and 20% test sets, preserving sentiment class balance\n",
    "# train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train) : Further splits training data into 90% training and 10% validation sets, keeping class distribution consistent\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f679be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Modeling:\n",
    "# 1. Architecting Model\n",
    "# 2. Compile Model\n",
    "# 3. Train Model\n",
    "# 4. Evaluate Model\n",
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ae23336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thedo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(output_dim = 16, input_dim=max_features, input_length = max_length))\n",
    "model.add(tf.keras.layers.SimpleRNN(units = 64, activation= 'tanh', return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(units= 1, activation= 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "331d634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs= 200, validation_data = (X_test, y_test), batch_size = 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
